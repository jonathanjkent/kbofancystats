# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
1+2
1+2 =4
library(tidyverse)
data <- read_csv("~research/data/exp_raw/tigaserver_app_fix.csv")
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
View(data)
summary(data)
library(ggmap)
register_google(key = "AIzaSyC8Mmv45YuMzDqM5_BML_35-j5HaSeTyZ4")
spain <-  get_googlemap(center = "Spain", zoom = 6)
spain <-  get_googlemap("Spain", zoom = 6)
spain <-  get_map("Spain", zoom = 6)
?get_googlemap
spain <-  get_map("Madric, Spain", zoom = 6)
g
get_googlemap("waco, texas", maptype = "satellite") %>% ggmap()
register_google(key = "AIzaSyC8Mmv45YuMzDqM5_BML_35-j5HaSeTyZ4")
register_google(key = "AIzaSyAwysDpKGsfTWgDMMDh071KiC-cYPWrXEY")
spain <-  get_map("Madric, Spain", zoom = 6)
ggmap(spain)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = data)
library(ggplot2)
bcn <-  get_map("Barcelona, Spain", zoom = 12)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = data)
data$grid.sq <- paste0(data$masked_lon,"x",data$masked_lat)
by.sq <- data %>% group_by(grid.sq) %>% count()
View(by.sq)
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(n)
View(by.sq)
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(desc(n)
by.sq[1,2]
by.sq[2,1]
by.sq[5,1]
topten <- by.sq[1:10,1]
toptenlocs <- data %>% filter(grid.sq %in% topten)
toptenlocs <- data %>% filter(grid.sq %in% as.list(topten))
topten <- as.list(by.sq[1:10,1])
topten <- as.vector(by.sq[1:10,1])
topten <- as.character(by.sq[1:10,1])
toptenlocs <- data %>% filter(grid.sq %in% topten)
topten
topten <- as.vector(by.sq[1:10,1])
topten
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
View(toptenlocs)
toptenlocs <- data %>% filter(grid.sq %in% c("-0.025x39.925", "-0.025x39.95 "))
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(desc(n))
by.sq
topten <- by.sq[1:10,1]
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Madrid, Spain", zoom = 4)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
View(topten)
spain <-  get_map("Madrid, Spain", zoom = 6)
topten <- by.sq[1:100,1]
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Zaragoza, Spain", zoom = 6)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Valencia, Spain", zoom = 6)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
View(by.sq)
test.sq <- data %>% filter(grid.sq == "2.05x41.55")
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
bcn <-  get_map("Barcelona, Spain", zoom = 12)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
bcn <-  get_map("Barcelona, Spain", zoom = 10)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Sabadell, Spain", zoom = 13)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Sabadell, Spain", zoom = 12)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Torrebonica, Spain", zoom = 13)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
View(test.sq)
test.sq$fake_lon <- test.sq$masked_lon - runif(1, 0, .025)
test.sq$fake_lat <- test.sq$masked_lat - runif(1, 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
test.sq$fake_lat <- test.sq$masked_lat + runif(1, 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
test.sq$fake_lon <- test.sq$masked_lon - runif(nrow(test.sq), 0, .025)
test.sq$fake_lat <- test.sq$masked_lat + runif(nrow(test.sq), 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq,alpha = 0.05)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.2)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.1)
data$fake_lon <- data$masked_lon - runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
bcn <-  get_map("Barcelona, Spain", zoom = 15)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
bcn <-  get_map("Barcelona, Spain", zoom = 14)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
bcn <-  get_map("Barcelona, Spain", zoom = 13)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 13)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 11)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
View(data)
library(tidyverse)
library(rvest)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(.byline-contributor-link)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(".byline-contributor-link")
d
library(tidyverse)
library(sf)
# Load Data as SF Objects
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
data$fake_lon <- data$masked_lon + runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
points <- data %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
polys <- st_transform(polys, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Point in polygon function
polys$pt_count <- lengths(st_intersects(polys, points))
View(polys)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
View(income)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
View(income)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
income$Renta_Hogar <- as.numeric(income$Renta_Hogar)
income$Renta_Persona <- as.numeric(income$Renta_Persona)
View(polys)
?sep
income <- income %>% separate(Area, c("CUSEC", "NMUN"))
income
# Add to ploys df
ploys <- polys %>% left_join(income, by = "CUSEC")
summary(polys)
summary(ploys)
# Add to ploys df
polys <- polys %>% left_join(income, by = "CUSEC")
library(tidyverse)
library(sf)
# Load Data as SF Objects
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
data$fake_lon <- data$masked_lon + runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
points <- data %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
polys <- st_transform(polys, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Point in polygon function
polys$pt_count <- lengths(st_intersects(polys, points))
# Collapse by community or municipality
#communities <- st_make_valid(polys) %>% group_by(NCA) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
#municipalities <- st_make_valid(polys) %>% group_by(NMUN) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
income$Renta_Persona <- as.numeric(income$Renta_Persona)
income$Renta_Hogar <- as.numeric(income$Renta_Hogar)
income <- income %>% separate(Area, c("CUSEC", "NMUN"))
# Add to ploys df
polys <- polys %>% left_join(income, by = "CUSEC")
library(ggplot2)
ggplot(polys,aes(Renta_Hogar,pt_count))
ggplot(polys,aes(Renta_Hogar,pt_count)) + geom_point()
# Twitter data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets
points <- data %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys$tw_count <- lengths(st_intersects(polys, tweets))
summary(polys)
ggplot(polys,aes(tw_count,pt_count)) + geom_point()
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(data), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(data), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(data), 0, .025)
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN"))
districts <- districts %>% left_join(income, by = "CUSEC")
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
ggplot(districts,aes(tw_pct,bt_pct)) + geom_point()
districts$more_tweets <- districts$tw_pct - districts$bt_pct
ggplot(districts,aes(more_tweets,renta_hogar)) + geom_point()
ggplot(districts,aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
ggplot(filter(districts, tw_count>0),aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
filter(districts, tw_count>0),
filter(districts, tw_count>0)
filter(districts, tw_count>10)
ggplot(filter(districts, tw_count>10),aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
View(districts)
# Collapse by community or municipality
#communities <- st_make_valid(polys) %>% group_by(NCA) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count)) %>% summarise(tw_count = sum(tw_count))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count))
View(tweets)
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
View(districts)
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
# Collapse by community or municipality
#communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise(bt_count = sum(bt_count)) %>% arrange(desc(obs))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count)) %>% summarise(tw_count = sum(tw_count))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count))
munitweets <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(tw_count = sum(tw_count))
municipalities <- municipalities %>% left_join(munitweets, by = "NMUN")
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
View(municipalities)
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
View(communities)
communities
communities %>% arrange(more_tweets)
municipalities %>% arrange(more_tweets)
# CSV exports
write_csv(communities, "~/research/communities.csv")
write_csv(municipalities, "~/research/municipalities.csv")
municipalities %>% arrange(desc(more_tweets)
)
# Names of all required packages that we will be using during the course
all_pkgs <- c('tidyverse', 'jtools', 'sjPlot','ggplot2','ggthemes','haven','foreign','essurvey','stargazer','knitr','prais','orcutt','fastDummies')
# Install all the packages (it may take a few minutes to install all of them)
install.packages(all_pkgs, dependencies = TRUE)
# Verify the installation worked correctly
setdiff(all_pkgs, row.names(installed.packages()))
library(essurvey)
?essurvey
# FutStat.cat
source("~/Google Drive/Futbol/futstat.R")
library(tidyverse)
library(sf)
tweets <- read_csv("~/research/tweets_jul1_sep15.csv")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
plot(tweets)
plot(tweets["timestamp"])
library(tidyverse)
library(sf)
# Load background track data
bgtracks <- readRDS("~/research/data/exp_pro/user_locations_small_cell.rds")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- read_csv("~/research/tweets_jul1_sep15.csv")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$bt_vs_tweets <- districts$bt_pct - districts$tw_pct
## Collapse by autonomous community and municipality
# CCAA
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities <- communities %>% filter(NCA != "Pais Vasco")
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$bt_vs_tweets <- communities$bt_pct -communities$tw_pct
ccaadata <- read_csv("~/research/ccaapopincome.csv")
communities <- communities %>% left_join(ccaadata, by = "NCA")
communities$pop_pct <- communities$population/sum(communities$population)
communities$bt_vs_pop <- communities$bt_pct - communities$pop_pct
# CCAA Analysis: no added value using tweets, no relationship w/ income
cor(communities$bt_vs_pop, communities$bt_vs_tweets)
#summary(lm(more_tweets ~ income, data = communities %>% filter(bt_count > 20)))
#ggplot(communities %>% filter(bt_count > 20)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
# Municipalities
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$bt_vs_tweets <- municipalities$bt_pct - municipalities$tw_pct
#st_geometry(municipalities) <- NULL
munidata <- read_csv("~/research/munipopincome.csv")
municipalities <- municipalities %>% left_join(munidata, by = "NMUN")
municipalities$pop_pct <- municipalities$population/sum(municipalities$population, na.rm = T)
municipalities$bt_vs_pop <- municipalities$bt_pct - municipalities$pop_pct
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities$bt_vs_pop, municipalities$bt_vs_tweets, use = "complete.obs")
#summary(lm(more_pop ~ more_tweets, data = municipalities %>% filter(bt_count > 0)))
#summary(lm(bt_count ~ income + pop_pct, data = municipalities %>% filter(bt_count > 0)))
#ggplot(municipalities %>% filter(bt_count > 0 & more_tweets < .02 & more_tweets > -.02)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
#ggplot(municipalities %>% filter(bt_count > 0 & bt_count < 1500)) + geom_point(aes(income, bt_count)) + geom_smooth(aes(income, bt_count), method = 'lm')
#ggplot(municipalities %>% filter(bt_count > 0 & more_tweets > -.02 & more_tweets < .02)) + geom_point(aes(more_tweets, more_pop)) + geom_smooth(aes(more_tweets, more_pop), method = 'lm')
#municipalities %>% arrange(desc(suburbs)) %>% select(NMUN,suburbs,tw_count)
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv") %>% select(-renta_persona)
population <- read_csv("~/research/popbybarri.csv")
population$CUSEC <- as.character(population$CUSEC)
income$renta_hogar <- as.numeric(income$renta_hogar)
names(income)[2] <- "income"
income <- income %>% separate(area, c("CUSEC"))
districts <- districts %>% left_join(income, by = "CUSEC")
districts <- districts %>% left_join(population, by = "CUSEC")
districts$pop_pct <- districts$population/sum(districts$population, na.rm = T)
districts$bt_vs_pop <- districts$bt_pct - districts$pop_pct
# Analysis: no relationship
cor(districts$bt_vs_pop, districts$bt_vs_tweets, use = "complete.obs")
summary(lm(bt_vs_pop ~ income, data = municipalities %>% filter(tw_count > 0 & bt_count > 0)))
summary(lm(bt_vs_pop ~ income, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
ggplot() +
geom_point(data = municipalities %>% filter(tw_count > 0 & bt_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.05), aes(income, bt_vs_tweets)) +
geom_smooth(data = municipalities  %>% filter(tw_count > 0 & bt_count > 0), aes(income, bt_vs_tweets), method = 'lm')
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts  %>% filter(tw_count > 0 & bt_count > 0), aes(income, bt_vs_tweets), method = 'lm')
# Simplify and save
#st_geometry(communities) <- NULL
#st_geometry(municipalities) <- NULL
#st_geometry(districts) <- NULL
#districts <- districts %>% select(CUSEC, NMUN, bt_count, tw_count, bt_pct, tw_pct, bt_vs_tweets, population, income, pop_pct, bt_vs_pop)
#write_csv(communities, "~/research/ccaa_datasimple.csv")
#write_csv(municipalities, "~/research/muni_datasimple.csv")
#write_csv(districts, "~/research/tract_datasimple.csv")
# Plots and Maps
ccaa <- communities %>% filter(NCA != "Canarias") %>% filter(NCA != "Ceuta") %>% filter(NCA != "Melilla")
plot(ccaa["bt_vs_tweets"],breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(ccaa["bt_vs_pop"],breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15,.25))
# Madrid
madrid <- st_make_valid(districts) %>% filter(NCA == "Comunidad de Madrid") %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
madrid$bt_pct <- madrid$bt_count/sum(madrid$bt_count)
madrid$tw_pct <- madrid$tw_count/sum(madrid$tw_count)
madrid$bt_vs_tweets <- madrid$bt_pct - madrid$tw_pct
munidata <- read_csv("~/research/munipopincome.csv")
madrid <- madrid %>% left_join(munidata, by = "NMUN")
madrid$pop_pct <- madrid$population/sum(madrid$population, na.rm = T)
madrid$bt_vs_pop <- madrid$bt_pct - madrid$pop_pct
madrid2 <- madrid %>% filter(tw_count > 1 & bt_count > 1 & population > 0)
# BCN
bcn <- st_make_valid(districts) %>% filter(NPRO == "Barcelona") %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
bcn$bt_pct <- bcn$bt_count/sum(bcn$bt_count)
bcn$tw_pct <- bcn$tw_count/sum(bcn$tw_count)
bcn$bt_vs_tweets <- bcn$bt_pct - bcn$tw_pct
munidata <- read_csv("~/research/munipopincome.csv")
bcn <- bcn %>% left_join(munidata, by = "NMUN")
bcn$pop_pct <- bcn$population/sum(bcn$population, na.rm = T)
bcn$bt_vs_pop <- bcn$bt_pct - bcn$pop_pct
bcn %>% arrange(desc(bt_count))
bcn2 <- bcn %>% filter(tw_count > 1 & bt_count > 1 & population > 0)
# City maps
plot(bcn2["bt_vs_pop"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(bcn2["bt_vs_tweets"], breaks = c(-.43,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(madrid2["bt_vs_pop"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(madrid2["bt_vs_tweets"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
sum(communities$tw_count)
communities %>% arrange(income)
# KBO Fancy Stats
source("~/Google Drive/KBO/2020elo.R")
names(districts)
plot(ccaa["bt_vs_tweets"],breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(ccaa["bt_vs_pop"],breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15,.25))
plot(madrid2["bt_vs_pop"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(madrid2["bt_vs_tweets"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
tail(madrid2 %>% arrange(bt_vs_pop))
tail(madrid2 %>% arrange(bt_vs_tweets))
View(madrid2)
plot(bcn2["bt_vs_pop"], breaks = c(-.2,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
plot(bcn2["bt_vs_tweets"], breaks = c(-.43,-.15,-.10,-.075,-.05,-.025,0,.025,.05,.075,.1,.15))
summary(municipalities$bt_count)
summary(lm(bt_vs_pop ~ income, data = municipalities))
summary(lm(bt_vs_pop ~ income, data = districts))
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm')
3.832e-07
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_count > -1 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm')
summary(lm(bt_vs_pop ~ income, data = districts))
summary(lm(bt_vs_tweets ~ income, data = districts))
summary(lm(bt_vs_tweets ~ income, data = municipalities))
summary(lm(bt_vs_tweets ~ income, data = districts))
ggplot() +
geom_point(data = districts %>% filter(bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm')
ggplot() +
geom_point(data = municipalities %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.05), aes(income, bt_vs_tweets)) +
geom_smooth(data = municipalities, aes(income, bt_vs_tweets), method = 'lm')
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_pop)) +
geom_smooth(data = districts, aes(income, bt_vs_pop), method = 'lm')
summary(lm(bt_vs_pop ~ income, data = municipalities))
summary(lm(bt_vs_pop ~ income, data = districts))
summary(lm(bt_vs_tweets ~ income, data = municipalities))
summary(lm(bt_vs_tweets ~ income, data = districts))
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm')
head(districts %>% arrange(desc(income)))
districts$income <- districts$income * 1000
head(districts %>% arrange(desc(income)))
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm')
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm') +
theme_minimal()
ggplot() +
geom_point(data = municipalities %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.05), aes(income, bt_vs_tweets)) +
geom_smooth(data = municipalities, aes(income, bt_vs_tweets), method = 'lm') +
theme_minimal()
ggplot() +
geom_point(data = municipalities %>% filter(tw_count > 0 & bt_vs_tweets < .02 & bt_vs_tweets > -.02), aes(income, bt_vs_tweets)) +
geom_smooth(data = municipalities, aes(income, bt_vs_tweets), method = 'lm') +
theme_minimal()
ggplot() +
geom_point(data = municipalities %>% filter(tw_count > 0 & bt_vs_tweets < .02 & bt_vs_tweets > -.02), aes(income, bt_vs_tweets)) +
geom_smooth(data = municipalities, aes(income, bt_vs_tweets), method = 'lm') +
theme_minimal() + labs(x="",y="")
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_tweets), method = 'lm') +
theme_minimal() + labs(x="",y="")
ggplot() +
geom_point(data = districts %>% filter(tw_count > 0 & bt_vs_tweets < .05 & bt_vs_tweets > -.01), aes(income, bt_vs_tweets)) +
geom_smooth(data = districts, aes(income, bt_vs_pop), method = 'lm') +
theme_minimal() + labs(x="",y="")
