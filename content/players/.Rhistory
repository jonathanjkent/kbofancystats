#Export the jsonlite function stream_in to the cluster
clusterExport(cluster,list("stream_in"))
#Create an empty list for the dataframe for each file
import <- list()
#Run this function on every file in the ./import directory
import <- parLapply(cluster,list.files(path = "./research"),function(file) {
#jsonlite function to convert the ndjson file to a dataframe
df <- stream_in(file(paste0("./research/",file)))
#select which columns to keep
df <- df[,c("geo","screen_name")]
return(df)
})
#Now you can stop the cluster
stopCluster(cluster)
library("jsonlite")
#Parallize this process on 16 threads
cluster <- makeCluster(4)
#Export the jsonlite function stream_in to the cluster
clusterExport(cluster,list("stream_in"))
#Create an empty list for the dataframe for each file
import <- list()
#Run this function on every file in the ./import directory
import <- parLapply(cluster,list.files(path = "./research"),function(file) {
#jsonlite function to convert the ndjson file to a dataframe
df <- stream_in(file(paste0("./research/",file)))
#select which columns to keep
df <- df[,c("geo","screen_name")]
return(df)
})
#function called from the data.table library
df <- rbindlist(import)
#Now you can stop the cluster
stopCluster(cluster)
library("data.table")
library("parallel")
library("jsonlite")
#Parallize this process on 16 threads
cluster <- makeCluster(4)
#Export the jsonlite function stream_in to the cluster
clusterExport(cluster,list("stream_in"))
#Create an empty list for the dataframe for each file
import <- list()
#Run this function on every file in the ./import directory
import <- parLapply(cluster,list.files(path = "./research"),function(file) {
#jsonlite function to convert the ndjson file to a dataframe
df <- stream_in(file(paste0("./research/",file)))
#select which columns to keep
df <- df[,c("geo","screen_name", "geo.type", "geo.coordinates")]
return(df)
})
#function called from the data.table library
df <- rbindlist(import)
#Now you can stop the cluster
stopCluster(cluster)
library("data.table")
library("parallel")
library("jsonlite")
#Parallize this process on 16 threads
cluster <- makeCluster(4)
#Export the jsonlite function stream_in to the cluster
clusterExport(cluster,list("stream_in"))
#Create an empty list for the dataframe for each file
import <- list()
#Run this function on every file in the ./import directory
import <- parLapply(cluster,list.files(path = "./research"),function(file) {
#jsonlite function to convert the ndjson file to a dataframe
df <- stream_in(file(paste0("./research/",file)))
#select which columns to keep
#df <- df[,c("geo","screen_name", "geo.type", "geo.coordinates")]
return(df)
})
#function called from the data.table library
df <- rbindlist(import)
#Now you can stop the cluster
stopCluster(cluster)
View(import)
df <- import[[1]]
View(df)
df1 <- df %>% select(geo)
library(tidyverse)
df1 <- df %>% select(geo)
View(df1)
length(import)
df1 <- df %>% subset(geo.type = "Point")
df1 <- df %>% subset(geo.type = "Point") %>% select(geo)
View(df1)
df1 <- df %>% select(geo) %>% subset(geo.type = "Point")
View(df1)
df2 <- df1 %>% subset(geo.type = "Point")
View(df1)
df2 <- df1[complete.cases(df1), ]
df1 <- df1[complete.cases(df1), ]
df1 <- as.data.frame(df1)
df1 <- df1[complete.cases(df1), ]
df2 <- df1 %>% subset(geo.type = "Point")
View(df1)
summary(df1)
df3 <- as.array(df1$coordinates)
df1 <- df1[complete.cases(df1$coordinates), ]
df1 <- df1$coordinates[complete.cases(df1$coordinates), ]
df1 <- df %>% select(geo.coordinates) %>% subset(geo.type = "Point")
df1 <- df %>% select(geo$coordinates) %>% subset(geo.type = "Point")
df2$geo.coordinates <- as.string(df2$geo.coordinates)
df2$geo.coordinates <- as.factor(df2$geo.coordinates)
df2$geo.coordinates <- as.array(df2$geo.coordinates)
df2 <- as.array(df2$geo.coordinates)
df2$geo.coordinates
coords <- select(df, coordinates.coordinates.1, coordinates.coordinates.0, coordinates.type, user.id)
View(import)
View(import)
df <- import[[1$geo]]
View(df)
df2 <- df[["geo"]]
View(df2)
df3 <- df2[["coordinates"]]
View(df3)
df4 <- as.data.frame(df3)
df4 <- as.array(df3)
View(df4)
df2 <- df[["coordinates"]]
View(df2)
df3 <- df[["geo"]]
View(df2)
df5 <- data.frame(matrix(unlist(df2), nrow=length(df2), byrow=T))
View(df5)
df5 <- data.frame(matrix(unlist(df2), nrow=length(df2), byrow=F))
df6 <- data.frame(matrix(unlist(df2), nrow=length(df2), byrow=F))
df10 <- do.call(rbind.data.frame, df2)
View(df10)
?unlist
View(df5)
View(df2)
View(df2)
df3 <- df2[[31]]
df3 <- df2[[31,]]
df3 <- df2[31]
df3 <- df2[31,]
View(df3)
df4 <- as.data.frame(df3)
View(df4)
df4$coordinates <- separate(df4$coordinates)
df4$coordinates <- unlist(df4$coordinates)
df4$coordinates <- unlist(df4$coordinates, byrow=T)
df4 <- unlist(df4)
df4 <- unlist(df2)
df4 <- unlist(df3)
df4 <- as.data.frame(unlist(df3))
View(df4)
df4 <- as.data.frame(unlist(df2))
df4 <- as.data.frame(unlist(df3))
View(df4)
df4 <- t(df4)
df4 <- as.data.frame(t(df4))
View(df4)
df4 <- as.data.frame(t(df4))
View(df4)
df4 <- as.data.frame(unlist(df2))
df4 <- as.data.frame(t(df4))
View(df4)
df4 <- as.data.frame(t(df4))
View(df4)
df2 <- df[["coordinates"]]
View(df2)
df4 <- as.data.frame(unlist(df2))
df1 <- df1[complete.cases(df2), ]
clean_data <- lapply(data_in, function(df2) x[complete.cases(x),])
library(lapply)
clean_data <- Map(na.omit, df2)
View(clean_data)
View(import)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:5), date=last(iran$date) + 1:5, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(iran)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Spain") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Italy") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Spain") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:30), date=last(iran$date) + 1:30, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
1+2
1+2 =4
library(tidyverse)
setwd("~/Google Drive/KBO/kbofancystats/content/teams")
batters <- read_csv("~/Google Drive/KBO/batters_simple.csv")
pitchers <- read_csv("~/Google Drive/KBO/pitchers_simple.csv")
list <- batters %>% subset(Season == "2019") %>% select(Team)
list <- unique(list$Team)
batleaders <- batters %>% select(Name.mykbo, Position, WAR, Season, Team)
pitleaders <- pitchers %>% select(Name.mykbo, Position, WAR, Season, Team)
leaders <- rbind(batleaders, pitleaders)
tops <- leaders %>% subset(Season == "2019") %>% group_by(Team) %>% top_n(3, WAR)
tops <- tops[order(-tops$WAR),]
tops$WAR <- round(tops$WAR, 2)
current.elos <- read_csv("~/Google Drive/KBO/currentelos.csv")
current.elos$Elo <- round(current.elos$Elo, 0)
setwd("~/Google Drive/KBO/kbofancystats/content/players")
list <- batters %>% subset(Season == "2019") %>% select(Name.mykbo, ID, KName, Team, Position)
for (i in 1:nrow(list)){
title <- paste0(list$Name.mykbo[i], " | ", list$KName[i])
subtitle <- paste0(list$Team[i], " | ", list$Position[i])
id <- list$ID[i]
a <- "---"
b <- paste0('title: ', title)
bb <- paste0('subtitle: ', subtitle)
bc <- 'summary: "Career Stats"'
c <- "```{r pressure, echo=F,warning=FALSE,message=FALSE}"
d <- "library(tidyverse)"
e <- "library(knitr)"
f <- "library(kableExtra)"
g <- 'batters <- read_csv("~/Google Drive/KBO/batters_simple.csv")'
h <- 'batters$Age <- as.numeric(batters$Age)'
j <- paste0('d <- batters %>% subset(ID == "', id, '") %>% select(-Name, -Name.mykbo, -KName, -Position, -ID)')
k <- 'd <- d[order(-d$Season),]'
l <- 'kable(d, digits = c(0,0,0,0,0,0,3,1,1,3,3,1,2), col.names = c("Season","Team","Age","G","PA","HR","OPS","BB%","SO%","ISO","BABIP","wRC+","WAR")) %>% kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T)'
m <- "```"
n <- '### Career Progression'
o <- "```{r, echo=F,warning=FALSE,message=FALSE}"
p <- 'library(ggplot2)'
q <- 'if(nrow(d) > 1){ggplot() + geom_line(aes(x = d$Age,y = d$wRCplus), size = 2, color = "#0f1b34") + theme_minimal() + labs(x = "Age", y = "wRC+")}'
file <- paste0(gsub("[[:space:]]", "", id), ".rmd")
writeLines(c(a,b,bb,bc,a,c,d,e,f,g,h,j,k,l,m,n,o,p,q,m), file)
}
setwd("~/Google Drive/KBO/kbofancystats/content/players")
list <- pitchers %>% subset(Season == "2019") %>% select(Name.mykbo, ID, KName, Team, Position)
for (i in 1:nrow(list)){
title <- paste0(list$Name.mykbo[i], " | ", list$KName[i])
subtitle <- paste0(list$Team[i], " | ", list$Position[i])
id <- list$ID[i]
a <- "---"
b <- paste0('title: ', title)
bb <- paste0('subtitle: ', subtitle)
bc <- 'summary: "Career Stats"'
c <- "```{r pressure, echo=F,warning=FALSE,message=FALSE}"
d <- "library(tidyverse)"
e <- "library(knitr)"
f <- "library(kableExtra)"
g <- 'pitchers <- read_csv("~/Google Drive/KBO/pitchers_simple.csv")'
j <- paste0('d <- pitchers %>% subset(ID == "', id, '") %>% select(-Name, -Name.mykbo, -KName, -Position, -ID)')
k <- 'd <- d[order(-d$Season),]'
l <- 'kable(d, digits = c(0,0,0,0,0,0,1,1,1,3,2,2,2), col.names = c("Season","Team","Age","G","GS","IP","K/9","BB/9","HR/9","BABIP","ERA","FIP","WAR")) %>% kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T)'
m <- "```"
n <- '### Career Progression'
o <- "```{r, echo=F,warning=FALSE,message=FALSE}"
p <- 'library(ggplot2)'
q <- 'if(nrow(d) > 1){ggplot() + geom_line(aes(x = d$Age,y = d$FIP), size = 2, color = "#0f1b34") + theme_minimal() + labs(x = "Age", y = "wRC+")}'
file <- paste0(gsub("[[:space:]]", "", id), ".rmd")
writeLines(c(a,b,bb,bc,a,c,d,e,f,g,j,k,l,m,n,o,p,q), file)
}
library(blogdown)
library(rmarkdown)
setwd("~/Google Drive/KBO/kbofancystats")
#render_site()
serve_site()
setwd("~/Google Drive/KBO/kbofancystats/content/players")
list <- pitchers %>% subset(Season == "2019") %>% select(Name.mykbo, ID, KName, Team, Position)
for (i in 1:nrow(list)){
title <- paste0(list$Name.mykbo[i], " | ", list$KName[i])
subtitle <- paste0(list$Team[i], " | ", list$Position[i])
id <- list$ID[i]
a <- "---"
b <- paste0('title: ', title)
bb <- paste0('subtitle: ', subtitle)
bc <- 'summary: "Career Stats"'
c <- "```{r pressure, echo=F,warning=FALSE,message=FALSE}"
d <- "library(tidyverse)"
e <- "library(knitr)"
f <- "library(kableExtra)"
g <- 'pitchers <- read_csv("~/Google Drive/KBO/pitchers_simple.csv")'
j <- paste0('d <- pitchers %>% subset(ID == "', id, '") %>% select(-Name, -Name.mykbo, -KName, -Position, -ID)')
k <- 'd <- d[order(-d$Season),]'
l <- 'kable(d, digits = c(0,0,0,0,0,0,1,1,1,3,2,2,2), col.names = c("Season","Team","Age","G","GS","IP","K/9","BB/9","HR/9","BABIP","ERA","FIP","WAR")) %>% kable_styling(bootstrap_options = c("striped", "hover"), fixed_thead = T)'
m <- "```"
n <- '### Career Progression'
o <- "```{r, echo=F,warning=FALSE,message=FALSE}"
p <- 'library(ggplot2)'
q <- 'if(nrow(d) > 1){ggplot() + geom_line(aes(x = d$Age,y = d$FIP), size = 2, color = "#0f1b34") + theme_minimal() + labs(x = "Age", y = "FIP")}'
file <- paste0(gsub("[[:space:]]", "", id), ".rmd")
writeLines(c(a,b,bb,bc,a,c,d,e,f,g,j,k,l,m,n,o,p,q), file)
}
