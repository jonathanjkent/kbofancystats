df4 <- as.data.frame(t(df4))
View(df4)
df2 <- df[["coordinates"]]
View(df2)
df4 <- as.data.frame(unlist(df2))
df1 <- df1[complete.cases(df2), ]
clean_data <- lapply(data_in, function(df2) x[complete.cases(x),])
library(lapply)
clean_data <- Map(na.omit, df2)
View(clean_data)
View(import)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:5), date=last(iran$date) + 1:5, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(iran)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Spain") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Italy") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "Spain") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:14), date=last(iran$date) + 1:14, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
library(readr)
library(tidyverse)
library(plotly)
library(ggplot2)
library(htmlwidgets)
## I'm not sure if all of those are needed but just install any of those you don't alrady have
# Read in and tidy data (this is just a bunch of tinkering John did with the original data)
D = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
mutate("country"=`Country/Region`) %>%
select(-one_of("Province/State", "Country/Region", "Lat", "Long")) %>%
pivot_longer(-country, names_to="date", values_to="cases") %>%
mutate(date=as.Date(date, format="%m/%d/%y")) %>%
group_by(country, date) %>%
summarise(cases=sum(cases))
#Select just Iran
iran <- D %>% subset(country == "US") %>% ungroup()
# Remove obsevations before there were any cases
iran <- iran %>% subset(cases > 0)
# Add today
#iran <- rbind(iran, c("Iran", "2020-03-10", 8042))
#iran$cases <- as.numeric(iran$cases)
#iran$date <- as.Date(iran$date)
# Create a variable that sets the first day as day 0 and then counts up
iran <- iran %>% mutate(days=as.integer(difftime(date, as.Date("2020-02-19"), units = "days")))
# Linear regression of the log of cases to find the growth rate
model <- lm(log(cases)~days, data=iran)
# Use that rate to predict the future
# If you want to do more than 5 days ahead, change the two 5s below but
# hopefully the rate will keep going down and this assumes it won't
future <- tibble(cases=last(iran$cases)*exp(model$coef[2]*1:30), date=last(iran$date) + 1:30, type="projected")
# Combine the actual cases with the projected ones
iran$type <- "actual"
iran <- iran %>% select(-country, -days)
iran <- rbind(iran, future)
# Make an graph (to easily save as an image)
ggplot(iran,aes(date, cases, color = type)) + geom_line()
# Make an interactive one
plot <- ggplot(iran,aes(date, cases, color = type)) + geom_line()
ggplotly(plot)
View(future)
1+2
1+2 =4
library(tidyverse)
data <- read_csv("~research/data/exp_raw/tigaserver_app_fix.csv")
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
View(data)
summary(data)
library(ggmap)
register_google(key = "AIzaSyC8Mmv45YuMzDqM5_BML_35-j5HaSeTyZ4")
spain <-  get_googlemap(center = "Spain", zoom = 6)
spain <-  get_googlemap("Spain", zoom = 6)
spain <-  get_map("Spain", zoom = 6)
?get_googlemap
spain <-  get_map("Madric, Spain", zoom = 6)
g
get_googlemap("waco, texas", maptype = "satellite") %>% ggmap()
register_google(key = "AIzaSyC8Mmv45YuMzDqM5_BML_35-j5HaSeTyZ4")
register_google(key = "AIzaSyAwysDpKGsfTWgDMMDh071KiC-cYPWrXEY")
spain <-  get_map("Madric, Spain", zoom = 6)
ggmap(spain)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = data)
library(ggplot2)
bcn <-  get_map("Barcelona, Spain", zoom = 12)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = data)
data$grid.sq <- paste0(data$masked_lon,"x",data$masked_lat)
by.sq <- data %>% group_by(grid.sq) %>% count()
View(by.sq)
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(n)
View(by.sq)
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(desc(n)
by.sq[1,2]
by.sq[2,1]
by.sq[5,1]
topten <- by.sq[1:10,1]
toptenlocs <- data %>% filter(grid.sq %in% topten)
toptenlocs <- data %>% filter(grid.sq %in% as.list(topten))
topten <- as.list(by.sq[1:10,1])
topten <- as.vector(by.sq[1:10,1])
topten <- as.character(by.sq[1:10,1])
toptenlocs <- data %>% filter(grid.sq %in% topten)
topten
topten <- as.vector(by.sq[1:10,1])
topten
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
View(toptenlocs)
toptenlocs <- data %>% filter(grid.sq %in% c("-0.025x39.925", "-0.025x39.95 "))
by.sq <- data %>% group_by(grid.sq) %>% count() %>% arrange(desc(n))
by.sq
topten <- by.sq[1:10,1]
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Madrid, Spain", zoom = 4)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
View(topten)
spain <-  get_map("Madrid, Spain", zoom = 6)
topten <- by.sq[1:100,1]
toptenlocs <- data %>% filter(grid.sq %in% topten$grid.sq)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Zaragoza, Spain", zoom = 6)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
spain <-  get_map("Valencia, Spain", zoom = 6)
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = toptenlocs)
View(by.sq)
test.sq <- data %>% filter(grid.sq == "2.05x41.55")
ggmap(spain) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
bcn <-  get_map("Barcelona, Spain", zoom = 12)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
bcn <-  get_map("Barcelona, Spain", zoom = 10)
ggmap(bcn) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Sabadell, Spain", zoom = 13)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Sabadell, Spain", zoom = 12)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
sabadell <-  get_map("Torrebonica, Spain", zoom = 13)
ggmap(sabadell) + geom_point(aes(x = masked_lon, y = masked_lat), data = test.sq)
View(test.sq)
test.sq$fake_lon <- test.sq$masked_lon - runif(1, 0, .025)
test.sq$fake_lat <- test.sq$masked_lat - runif(1, 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
test.sq$fake_lat <- test.sq$masked_lat + runif(1, 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
test.sq$fake_lon <- test.sq$masked_lon - runif(nrow(test.sq), 0, .025)
test.sq$fake_lat <- test.sq$masked_lat + runif(nrow(test.sq), 0, .025)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq,alpha = 0.05)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.2)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.1)
data$fake_lon <- data$masked_lon - runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
bcn <-  get_map("Barcelona, Spain", zoom = 15)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
bcn <-  get_map("Barcelona, Spain", zoom = 14)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
bcn <-  get_map("Barcelona, Spain", zoom = 13)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 13)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 11)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
View(data)
library(tidyverse)
library(rvest)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(.byline-contributor-link)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(".byline-contributor-link")
d
library(blogdown)
library(rmarkdown)
library(tidyverse)
library(rvest)
library(elo)
library(scales)
setwd("~/Google Drive/KBO")
## Scrape 2020 Schedule and Results
links <- read_csv("mykboweeks.csv")
links <- links$url
all.results <- NA
all.schedule <- NA
for (i in links){
print(i)
url <- i
week <- substring(url, first = 38)
d <- read_html(url) %>% html_table() %>% as.data.frame() %>% select(-X2, -X4)
d <- d[2:(nrow(d)-1),]
d <- d %>% filter(str_detect(X1, "2020") == F)
d <- d %>% separate(X1, c("away1", "away2"))
d <- d %>% separate(X5, c("home1", "home2"))
d <- d %>% separate(X3, c("A.Score", "H.Score"))
d$Away <- paste(d$away1, d$away2)
d$Home <- paste(d$home1, d$home2)
d$week <- as.Date(week)
d$Year <- 2020
d$addday <- rep(0:6, each = 5, length.out = nrow(d))
d$Date <- as.Date(d$week + d$addday)
results <- d %>% filter(!str_detect(H.Score, "0am") & !str_detect(A.Score, "Canceled")) %>% select(Date, Home, Away, H.Score, A.Score, Year)
schedule <- d %>% filter(str_detect(H.Score, "0am")) %>% select(Home, Away, Date, Year)
all.results <- rbind(all.results, results)
if (nrow(schedule) > 0) {
all.schedule <- rbind(all.schedule, schedule)
}
}
all.results <- all.results[2:nrow(all.results),]
all.schedule <- all.schedule[2:nrow(all.schedule),]
## Tally Current Win Totals
all.results <- mutate(all.results, Winner = ifelse(H.Score > A.Score, as.character(Home), as.character(Away)))
wins <- all.results %>% group_by(Winner) %>% count()
all.results <- all.results %>% select(-Winner)
## Read In Historical Results
kbohistory <- read_csv("kboresults.csv")
kbohistory$Date <- ISOdate(kbohistory$Year, kbohistory$Month, kbohistory$Day)
kbohistory <- kbohistory %>% select(Date, Home, Away, H.Score, A.Score, Year)
all.history <- rbind(kbohistory, all.results)
all.history <- all.history[order(all.history$Date),]
all.history$H.Score <- as.double(all.history$H.Score)
all.history$A.Score <- as.double(all.history$A.Score)
## Run Elo
elo <- elo.run(score(H.Score, A.Score) ~ adjust(Home, 24) + Away + regress(Year, 1500, 0.5) + k(4*(abs(H.Score - A.Score)^(1/4))), data = all.history)
all.history$H.Elo <- elo[[1]][,7]
all.history$A.Elo <- elo[[1]][,8]
## Create Elo History Table
home <- all.history %>% select(Date, Home, H.Elo)
away <- all.history %>% select(Date, Away, A.Elo)
cols <- c("Date", "Team", "Elo")
colnames(home) <- cols
colnames(away) <- cols
elo.history <- rbind(home,away)
elo.history$Elo <- round(elo.history$Elo, digits = 0)
## Current Elos
current.elos <- elo.history %>%
group_by(Team) %>%
arrange(desc(Date)) %>%
slice(1) %>% select(-Date) %>%
arrange(desc(Elo))
current.elos$Rank <- 1:10
write_csv(current.elos, "currentelos.csv")
## Ten Team Era for History Page
tenteam <- elo.history %>% filter(Date > ISOdate(2013,1,1))
write_csv(tenteam,"elohistory.csv")
## Simulations
nsim <- 100000
all.schedule$Prediction <- predict(elo, newdata = all.schedule)
all.schedule <- data.frame(all.schedule, Round = rep(1:nsim, each = nrow(all.schedule)))
all.schedule$Sim <- runif((nrow(all.schedule)),0,1)
all.schedule <- mutate(all.schedule, H.Win = ifelse(Sim < Prediction, 1, 0))
all.schedule <- mutate(all.schedule, Winner = ifelse(H.Win == 1, as.character(Home), as.character(Away)))
standings <- all.schedule %>% group_by(Winner, Round) %>% count()
standings <- standings %>% left_join(wins, by = "Winner")
standings$n.y[is.na(standings$n.y)] <- 0
standings$n <- standings$n.x + standings$n.y
standings <- standings %>% arrange(desc(n)) %>% arrange(Round)
standings$Rank <- rep(1:10, max(standings$Round))
pred.1 <- standings %>% filter(Rank == 1) %>% group_by(Winner) %>% count()
pred.1$Pct <- (pred.1$n/nsim)
colnames(pred.1) <- c("Winner", "n", "First")
pred.2 <- standings %>% filter(Rank == 2) %>% group_by(Winner) %>% count()
pred.2$Pct <- (pred.2$n/nsim)
colnames(pred.2) <- c("Winner", "n", "Second")
pred.3 <- standings %>% filter(Rank == 3) %>% group_by(Winner) %>% count()
pred.3$Pct <- (pred.3$n/nsim)
colnames(pred.3) <- c("Winner", "n", "Third")
pred.4 <- standings %>% filter(Rank == 4) %>% group_by(Winner) %>% count()
pred.4$Pct <- (pred.4$n/nsim)
colnames(pred.4) <- c("Winner", "n", "Fourth")
pred.5 <- standings %>% filter(Rank == 5) %>% group_by(Winner) %>% count()
pred.5$Pct <- (pred.5$n/nsim)
colnames(pred.5) <- c("Winner", "n", "Fifth")
pred.6 <- standings %>% filter(Rank > 5) %>% group_by(Winner) %>% count()
pred.6$Pct <- (pred.6$n/nsim)
colnames(pred.6) <- c("Winner", "n", "Out")
predictions <- ungroup(as.data.frame(standings$Winner[1:10]))
colnames(predictions) <- "Winner"
predictions <- pred.1 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions <- pred.2 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions <- pred.3 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions <- pred.4 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions <- pred.5 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions <- pred.6 %>% select(-n) %>% right_join(predictions, by = "Winner")
predictions$Team <- predictions$Winner
predictions <- predictions %>% left_join(current.elos, by = "Team")
predictions <- predictions %>% ungroup() %>% select(-Winner)
predictions <- predictions %>%
mutate(First = percent(First, 1)) %>%
mutate(Second = percent(Second, 1)) %>%
mutate(Third = percent(Third, 1)) %>%
mutate(Fourth = percent(Fourth, 1)) %>%
mutate(Fifth = percent(Fifth, 1)) %>%
mutate(Out = percent(Out, 1))
predictions <- predictions %>% select(Rank, Team, Elo, First, Second, Third, Fourth, Fifth, Out)
write_csv(predictions, "predictions.csv")
## Render Elo Pages
render("~/Google Drive/KBO/kbofancystats/content/elo.Rmd")
render("~/Google Drive/KBO/kbofancystats/content/elo2020.Rmd")
render("~/Google Drive/KBO/kbofancystats/content/elohistory.Rmd")
setwd("~/Google Drive/KBO/kbofancystats")
#stop_server()
serve_site()
## Homepage image
setwd("~/Google Drive/KBO/kbofancystats/static/img")
tenteam <- read_csv("~/Google Drive/KBO/elohistory.csv")
tenteam <- tenteam %>% subset(Date > ISOdate(2020,5,4))
tenteam$Team <- as.factor(tenteam$Team)
rank <- read_csv("~/Google Drive/KBO/currentelos.csv")
rank$Team2 <- paste0(rank$Team, " (",rank$Elo,")")
levels <- rank$Team2
tenteam <- tenteam %>% left_join(rank, by = "Team")
tenteam$Team2 <- as.factor(tenteam$Team2)
tenteam$Team2 <- factor(tenteam$Team2, levels = levels)
plot <- ggplot() + geom_line(data = tenteam, aes(Date, Elo.x, color = Team2)) + theme_minimal() + labs(x = "", y = "Elo", color = "")
ggsave("elo.png", width = 8, height = 3)
View(wins)
View(wins)
View(wins)
wins
View(all.results)
